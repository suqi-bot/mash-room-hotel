// ğŸ¤ è¯­éŸ³æ´»åŠ¨æ£€æµ‹(VAD)æœåŠ¡
// æ™ºèƒ½æ£€æµ‹ç”¨æˆ·è¯´è¯çš„å¼€å§‹å’Œç»“æŸï¼Œæ”¯æŒå®æ—¶è¯­éŸ³æ–­å¥

export interface VADConfig {
  // éŸ³é‡é˜ˆå€¼é…ç½®
  volumeThreshold: number
  silenceThreshold: number
  
  // æ—¶é—´é…ç½®
  minSpeechDuration: number  // æœ€å°è¯´è¯æ—¶é•¿(ms)
  maxSilenceDuration: number // æœ€å¤§é™éŸ³æ—¶é•¿(ms)
  debounceTime: number       // é˜²æŠ–æ—¶é—´(ms)
  
  // é¢‘ç‡åˆ†æé…ç½®
  fftSize: number
  smoothingTimeConstant: number
  
  // é«˜çº§é…ç½®
  useFrequencyAnalysis: boolean
  speechFrequencyRange: [number, number] // è¯­éŸ³é¢‘ç‡èŒƒå›´
}

export interface VADState {
  isSpeaking: boolean
  speechStartTime?: number
  speechEndTime?: number
  currentVolume: number
  averageVolume: number
  speechDuration: number
  silenceDuration: number
}

export interface VADEvents {
  onSpeechStart: () => void
  onSpeechEnd: () => void
  onVolumeChange: (volume: number) => void
  onStateChange: (state: VADState) => void
}

export class VoiceActivityDetection {
  private config: VADConfig
  private events: VADEvents
  private state: VADState
  
  // éŸ³é¢‘åˆ†æç›¸å…³
  private audioContext?: AudioContext
  private analyser?: AnalyserNode
  private mediaStreamSource?: MediaStreamAudioSourceNode
  
  // æ£€æµ‹çŠ¶æ€
  private isActive = false
  private animationFrame?: number
  
  // éŸ³é‡å†å²è®°å½•
  private volumeHistory: number[] = []
  private readonly historySize = 10
  
  // å®šæ—¶å™¨
  private speechTimer?: number
  private silenceTimer?: number
  
  constructor(config: Partial<VADConfig> = {}, events: Partial<VADEvents> = {}) {
    this.config = {
      volumeThreshold: 0.01,
      silenceThreshold: 0.005,
      minSpeechDuration: 300,
      maxSilenceDuration: 1500,
      debounceTime: 100,
      fftSize: 512,
      smoothingTimeConstant: 0.8,
      useFrequencyAnalysis: true,
      speechFrequencyRange: [80, 8000],
      ...config
    }
    
    this.events = {
      onSpeechStart: () => {},
      onSpeechEnd: () => {},
      onVolumeChange: () => {},
      onStateChange: () => {},
      ...events
    }
    
    this.state = {
      isSpeaking: false,
      currentVolume: 0,
      averageVolume: 0,
      speechDuration: 0,
      silenceDuration: 0
    }
  }

  /**
   * åˆå§‹åŒ–VAD
   */
  async initialize(mediaStream: MediaStream): Promise<void> {
    try {
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume()
      }
      
      // åˆ›å»ºåˆ†æå™¨
      this.analyser = this.audioContext.createAnalyser()
      this.analyser.fftSize = this.config.fftSize
      this.analyser.smoothingTimeConstant = this.config.smoothingTimeConstant
      
      // è¿æ¥åª’ä½“æµ
      this.mediaStreamSource = this.audioContext.createMediaStreamSource(mediaStream)
      this.mediaStreamSource.connect(this.analyser)
      
      console.log('VADåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      console.error('VADåˆå§‹åŒ–å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * å¼€å§‹è¯­éŸ³æ´»åŠ¨æ£€æµ‹
   */
  start(): void {
    if (!this.analyser || this.isActive) return
    
    this.isActive = true
    this.startDetection()
    console.log('VADæ£€æµ‹å·²å¼€å§‹')
  }

  /**
   * åœæ­¢è¯­éŸ³æ´»åŠ¨æ£€æµ‹
   */
  stop(): void {
    this.isActive = false
    
    if (this.animationFrame) {
      cancelAnimationFrame(this.animationFrame)
      this.animationFrame = undefined
    }
    
    this.clearTimers()
    console.log('VADæ£€æµ‹å·²åœæ­¢')
  }

  /**
   * é”€æ¯VAD
   */
  destroy(): void {
    this.stop()
    
    if (this.mediaStreamSource) {
      this.mediaStreamSource.disconnect()
      this.mediaStreamSource = undefined
    }
    
    if (this.audioContext && this.audioContext.state !== 'closed') {
      this.audioContext.close()
      this.audioContext = undefined
    }
    
    this.analyser = undefined
  }

  /**
   * å¼€å§‹æ£€æµ‹å¾ªç¯
   */
  private startDetection(): void {
    if (!this.isActive || !this.analyser) return
    
    const bufferLength = this.analyser.frequencyBinCount
    const dataArray = new Uint8Array(bufferLength)
    const frequencyArray = new Uint8Array(bufferLength)
    
    const detect = () => {
      if (!this.isActive || !this.analyser) return
      
      // è·å–æ—¶åŸŸæ•°æ®ï¼ˆéŸ³é‡ï¼‰
      this.analyser.getByteTimeDomainData(dataArray)
      
      // è·å–é¢‘åŸŸæ•°æ®ï¼ˆé¢‘ç‡åˆ†æï¼‰
      if (this.config.useFrequencyAnalysis) {
        this.analyser.getByteFrequencyData(frequencyArray)
      }
      
      // è®¡ç®—å½“å‰éŸ³é‡
      const volume = this.calculateVolume(dataArray)
      
      // é¢‘ç‡åˆ†æï¼ˆå¯é€‰ï¼‰
      const speechLikelihood = this.config.useFrequencyAnalysis 
        ? this.analyzeSpeechFrequency(frequencyArray)
        : 1
      
      // æ›´æ–°éŸ³é‡å†å²
      this.updateVolumeHistory(volume)
      
      // æ£€æµ‹è¯­éŸ³æ´»åŠ¨
      this.detectSpeechActivity(volume, speechLikelihood)
      
      // æ›´æ–°çŠ¶æ€
      this.updateState(volume)
      
      this.animationFrame = requestAnimationFrame(detect)
    }
    
    detect()
  }

  /**
   * è®¡ç®—éŸ³é‡
   */
  private calculateVolume(dataArray: Uint8Array): number {
    let sum = 0
    for (let i = 0; i < dataArray.length; i++) {
      const sample = (dataArray[i] - 128) / 128
      sum += sample * sample
    }
    return Math.sqrt(sum / dataArray.length)
  }

  /**
   * åˆ†æè¯­éŸ³é¢‘ç‡ç‰¹å¾
   */
  private analyzeSpeechFrequency(frequencyArray: Uint8Array): number {
    const sampleRate = this.audioContext!.sampleRate
    const binSize = sampleRate / this.config.fftSize
    
    const [minFreq, maxFreq] = this.config.speechFrequencyRange
    const minBin = Math.floor(minFreq / binSize)
    const maxBin = Math.floor(maxFreq / binSize)
    
    let speechEnergy = 0
    let totalEnergy = 0
    
    for (let i = 0; i < frequencyArray.length; i++) {
      const energy = frequencyArray[i] / 255
      totalEnergy += energy
      
      if (i >= minBin && i <= maxBin) {
        speechEnergy += energy
      }
    }
    
    return totalEnergy > 0 ? speechEnergy / totalEnergy : 0
  }

  /**
   * æ›´æ–°éŸ³é‡å†å²
   */
  private updateVolumeHistory(volume: number): void {
    this.volumeHistory.push(volume)
    if (this.volumeHistory.length > this.historySize) {
      this.volumeHistory.shift()
    }
  }

  /**
   * æ£€æµ‹è¯­éŸ³æ´»åŠ¨
   */
  private detectSpeechActivity(volume: number, speechLikelihood: number): void {
    const adjustedThreshold = this.config.volumeThreshold * speechLikelihood
    const isSpeechDetected = volume > adjustedThreshold
    
    if (isSpeechDetected && !this.state.isSpeaking) {
      // æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
      this.handleSpeechStart()
    } else if (!isSpeechDetected && this.state.isSpeaking) {
      // æ£€æµ‹åˆ°å¯èƒ½çš„è¯­éŸ³ç»“æŸ
      this.handlePossibleSpeechEnd()
    } else if (isSpeechDetected && this.state.isSpeaking) {
      // ç»§ç»­è¯´è¯ï¼Œé‡ç½®é™éŸ³è®¡æ—¶å™¨
      this.clearSilenceTimer()
    }
  }

  /**
   * å¤„ç†è¯­éŸ³å¼€å§‹
   */
  private handleSpeechStart(): void {
    this.clearTimers()
    
    // è®¾ç½®æœ€å°è¯´è¯æ—¶é•¿æ£€æŸ¥
    this.speechTimer = window.setTimeout(() => {
      if (!this.state.isSpeaking) {
        this.state.isSpeaking = true
        this.state.speechStartTime = Date.now()
        this.events.onSpeechStart()
        this.events.onStateChange(this.state)
      }
    }, this.config.debounceTime)
  }

  /**
   * å¤„ç†å¯èƒ½çš„è¯­éŸ³ç»“æŸ
   */
  private handlePossibleSpeechEnd(): void {
    if (!this.state.isSpeaking) return
    
    this.clearSilenceTimer()
    
    // è®¾ç½®é™éŸ³æ£€æµ‹è®¡æ—¶å™¨
    this.silenceTimer = window.setTimeout(() => {
      this.handleSpeechEnd()
    }, this.config.maxSilenceDuration)
  }

  /**
   * å¤„ç†è¯­éŸ³ç»“æŸ
   */
  private handleSpeechEnd(): void {
    if (!this.state.isSpeaking) return
    
    const now = Date.now()
    const speechDuration = this.state.speechStartTime ? now - this.state.speechStartTime : 0
    
    // æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°è¯´è¯æ—¶é•¿
    if (speechDuration >= this.config.minSpeechDuration) {
      this.state.isSpeaking = false
      this.state.speechEndTime = now
      this.state.speechDuration = speechDuration
      
      this.events.onSpeechEnd()
      this.events.onStateChange(this.state)
    }
    
    this.clearTimers()
  }

  /**
   * æ›´æ–°çŠ¶æ€
   */
  private updateState(volume: number): void {
    this.state.currentVolume = volume
    this.state.averageVolume = this.volumeHistory.reduce((a, b) => a + b, 0) / this.volumeHistory.length
    
    if (this.state.isSpeaking && this.state.speechStartTime) {
      this.state.speechDuration = Date.now() - this.state.speechStartTime
    }
    
    this.events.onVolumeChange(volume)
    this.events.onStateChange(this.state)
  }

  /**
   * æ¸…é™¤å®šæ—¶å™¨
   */
  private clearTimers(): void {
    this.clearSpeechTimer()
    this.clearSilenceTimer()
  }

  private clearSpeechTimer(): void {
    if (this.speechTimer) {
      clearTimeout(this.speechTimer)
      this.speechTimer = undefined
    }
  }

  private clearSilenceTimer(): void {
    if (this.silenceTimer) {
      clearTimeout(this.silenceTimer)
      this.silenceTimer = undefined
    }
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getState(): VADState {
    return { ...this.state }
  }

  /**
   * åŠ¨æ€è°ƒæ•´é˜ˆå€¼
   */
  adjustThreshold(threshold: number): void {
    this.config.volumeThreshold = Math.max(0, Math.min(1, threshold))
  }

  /**
   * è·å–å¹³å‡éŸ³é‡ï¼ˆç”¨äºè‡ªåŠ¨æ ¡å‡†ï¼‰
   */
  getAverageVolume(): number {
    return this.state.averageVolume
  }
}
